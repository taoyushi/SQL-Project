# self_correction/self_correction_module.py
import re
import os
import logging
import json
import time
import random
from typing import Dict, Any, Tuple, Optional
from .prompt_generator import PromptGenerator, PromptStrategy
from .llm_api import QwenAPIClient, LLMError
from .sql_validator import SQLValidator, ExecutionResult
from .config import SelfCorrectionConfig

# Configure logging
logger = logging.getLogger(__name__)

class SelfCorrectionModule:
    """
    æ ¸å¿ƒè‡ªä¿®æ­£æ¨¡å—ï¼Œé›†æˆ Prompt Generation, LLM Interaction, SQL Validation,
    å’Œ Fallback Logic to correct initial SQL queries.
    """

    def __init__(self, config: SelfCorrectionConfig):
        """
        åˆå§‹åŒ–è‡ªä¿®æ­£æ¨¡å—ã€‚

        Args:
            config (SelfCorrectionConfig): é…ç½®å¯¹è±¡ï¼ŒåŒ…å« LLM API è®¾ç½®ã€Prompt ç­–ç•¥ç­‰ã€‚
        """
        self.config = config
        
        # éªŒè¯é…ç½®
        if not config.validate_config():
            raise ValueError("Invalid configuration provided")
            
        self.prompt_generator = PromptGenerator(config.prompt_templates, config.few_shot_examples)
        self.llm_client = QwenAPIClient(
            api_key=config.llm_api_key,
            endpoint=config.llm_api_endpoint,
            model=config.llm_model_name,
            timeout=config.llm_timeout_seconds,
            max_retries=config.llm_max_retries
        )
        self.sql_validator = SQLValidator(timeout_seconds=30)
        self.log_dir = config.log_dir

        # Ensure log directory exists
        os.makedirs(self.log_dir, exist_ok=True)
        logger.info(f"SelfCorrectionModule initialized with log directory: {self.log_dir}")
        
        # Test API connection
        if not self._test_api_connection():
            logger.warning("API connection test failed. Corrections may fail.")

    def _test_api_connection(self) -> bool:
        """æµ‹è¯•APIè¿æ¥"""
        try:
            return self.llm_client.test_connection()
        except Exception as e:
            logger.error(f"API connection test error: {e}")
            return False

    def process(self, nlq: str, schema: Dict[str, Any], initial_sql: str, db_path: str) -> Tuple[str, str]:
        """
        æ™ºèƒ½å¤„ç†ï¼šä½¿ç”¨æ›´æ™ºèƒ½çš„ç­–ç•¥åˆ¤æ–­æ˜¯å¦éœ€è¦ä¿®æ­£
        """
        db_id = os.path.basename(os.path.dirname(db_path)) if os.path.dirname(db_path) else "unknown"

        correction_log = {
            "question": nlq,
            "db_id": db_id,
            "initial_sql": initial_sql,
            "corrected_sql_llm": None,
            "final_sql_output": initial_sql,
            "initial_sql_executable": False,
            "corrected_sql_executable": False,
            "validation_error": None,
            "correction_status": "correction_failed",
            "prompt_used": None,
            "llm_api_log_id": None,
            "processing_time_ms": 0,
            "correction_reason": None
        }
        start_time = time.time()

        try:
            # 1. é¦–å…ˆéªŒè¯åˆå§‹SQL
            initial_validation_result = self._validate_sql(initial_sql, db_path)
            correction_log["initial_sql_executable"] = initial_validation_result.is_executable
            
            # ğŸ¯ ä¿®æ”¹ç­–ç•¥ï¼šæ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦ä¿®æ­£
            should_attempt_correction, reason = self._should_attempt_correction(
                initial_sql, initial_validation_result, nlq
            )
            correction_log["correction_reason"] = reason
            
            if not should_attempt_correction:
                logger.info(f"Skipping correction for DB {db_id} - {reason}")
                correction_log["correction_status"] = "no_correction_needed"
                correction_log["final_sql_output"] = initial_sql
                self._save_log(correction_log)
                correction_log["processing_time_ms"] = (time.time() - start_time) * 1000
                return initial_sql, "no_correction_needed"
            
            # 2. éœ€è¦ä¿®æ­£æ—¶ï¼Œç”Ÿæˆé€‚å½“çš„Prompt
            logger.info(f"Attempting correction for DB {db_id} - {reason}")
            
            if not initial_validation_result.is_executable:
                hint = self._generate_guided_hint(initial_sql, initial_validation_result.error_message)
                prompt_strategy = PromptStrategy.GUIDED
            else:
                hint = self._generate_improvement_hint(initial_sql, nlq, reason)
                prompt_strategy = PromptStrategy.GUIDED

            # 3. ç”Ÿæˆä¿å®ˆçš„Prompt
            schema_text = self._format_schema_for_prompt(schema)
            prompt = self.prompt_generator.generate_prompt(
                nlq=nlq,
                schema_context=schema_text,
                initial_sql=initial_sql,
                strategy=prompt_strategy,
                hint=hint
            )
            correction_log["prompt_used"] = prompt
            logger.debug(f"Generated prompt for DB {db_id}: {prompt[:500]}...")

            # 4. è°ƒç”¨ LLM API
            try:
                logger.info(f"Calling LLM for DB {db_id}...")
                llm_response_raw = self.llm_client.get_correction(
                    prompt=prompt,
                    temperature=self.config.llm_temperature,
                    max_tokens=self.config.llm_max_tokens,
                    stop_sequences=self.config.llm_stop_sequences
                )
                logger.debug(f"LLM response for DB {db_id}: {llm_response_raw[:500]}...")
            except LLMError as e:
                logger.error(f"LLM API call failed for DB {db_id}: {e}")
                correction_log["validation_error"] = f"LLM API Error: {e}"
                correction_log["correction_status"] = "api_error"
                self._save_log(correction_log)
                correction_log["processing_time_ms"] = (time.time() - start_time) * 1000
                return initial_sql, correction_log["correction_status"]

            # 5. è§£æ LLM å“åº”
            corrected_sql = self._parse_llm_response(llm_response_raw)
            correction_log["corrected_sql_llm"] = corrected_sql
            logger.debug(f"Parsed corrected SQL for DB {db_id}: {corrected_sql}")

            corrected_validation_result = ExecutionResult(False, "No corrected SQL to validate")
            if corrected_sql:
                # 6. éªŒè¯ä¿®æ­£åçš„ SQL
                corrected_validation_result = self._validate_sql(corrected_sql, db_path)
                correction_log["corrected_sql_executable"] = corrected_validation_result.is_executable
                if not corrected_validation_result.is_executable:
                    correction_log["validation_error"] = corrected_validation_result.error_message
                    logger.warning(f"Corrected SQL is not executable for DB {db_id}: {corrected_validation_result.error_message}")
            else:
                logger.warning(f"LLM returned empty or unparseable SQL for DB {db_id}")
                correction_log["validation_error"] = "LLM returned empty or unparseable SQL"

            # 7. åº”ç”¨æ™ºèƒ½å›é€€ç­–ç•¥
            final_sql, correction_status = self._apply_intelligent_fallback_strategy(
                initial_sql,
                initial_validation_result,
                corrected_sql if corrected_sql else initial_sql,
                corrected_validation_result
            )
            correction_log["final_sql_output"] = final_sql
            correction_log["correction_status"] = correction_status
            logger.info(f"Final SQL decision for DB {db_id}: {correction_status}")

        except Exception as e:
            logger.error(f"Unexpected error during correction for DB {db_id}: {e}", exc_info=True)
            correction_log["validation_error"] = f"Unexpected internal error: {e}"
            correction_log["correction_status"] = "internal_error"
            final_sql = initial_sql
            correction_status = "internal_error"

        finally:
            correction_log["processing_time_ms"] = (time.time() - start_time) * 1000
            self._save_log(correction_log)
            return correction_log["final_sql_output"], correction_log["correction_status"]

    def _should_attempt_correction(self, sql: str, validation_result: ExecutionResult, nlq: str) -> Tuple[bool, str]:
        """æ™ºèƒ½åˆ¤æ–­æ˜¯å¦åº”è¯¥å°è¯•ä¿®æ­£SQL"""
        
        # 1. ä¸å¯æ‰§è¡Œçš„SQLå¿…é¡»ä¿®æ­£
        if not validation_result.is_executable:
            return True, "SQLä¸å¯æ‰§è¡Œ"
        
        # 2. å¯æ‰§è¡Œä½†è¿”å›ç©ºç»“æœçš„SQLå¯èƒ½æœ‰é—®é¢˜  
        if hasattr(validation_result, 'result_count') and validation_result.result_count == 0:
            return True, "SQLå¯æ‰§è¡Œä½†è¿”å›ç©ºç»“æœ"
        
        # 3. æ£€æŸ¥å¸¸è§é”™è¯¯æ¨¡å¼
        error_patterns = [
            (r'\bstudents\b', 'table_name_plural'),
            (r'\bsingers\b', 'table_name_plural'), 
            (r'\bName\b', 'column_name_case'),
            (r'\bPopulation\b', 'column_name_case'),
            (r'\bAge\b', 'column_name_case'),
            (r'FROM\s+\w+\s+WHERE\s+\w+\.\w+', 'possible_redundant_reference'),
        ]
        
        for pattern, error_type in error_patterns:
            if re.search(pattern, sql, re.IGNORECASE):
                return True, f"å‘ç°å¯èƒ½é”™è¯¯æ¨¡å¼: {error_type}"
        
        # 4. åŸºäºé—®é¢˜ç±»å‹çš„å¯å‘å¼åˆ¤æ–­
        nlq_lower = nlq.lower()
        
        if 'how many' in nlq_lower and 'count(' not in sql.lower():
            return True, "é—®é¢˜è¯¢é—®æ•°é‡ä½†SQLä¸­æ— countå‡½æ•°"
        
        if 'average' in nlq_lower and 'avg(' not in sql.lower():
            return True, "é—®é¢˜è¯¢é—®å¹³å‡å€¼ä½†SQLä¸­æ— avgå‡½æ•°"
            
        if 'maximum' in nlq_lower and 'max(' not in sql.lower():
            return True, "é—®é¢˜è¯¢é—®æœ€å¤§å€¼ä½†SQLä¸­æ— maxå‡½æ•°"
            
        if 'minimum' in nlq_lower and 'min(' not in sql.lower():
            return True, "é—®é¢˜è¯¢é—®æœ€å°å€¼ä½†SQLä¸­æ— minå‡½æ•°"
        
        # 5. æ£€æŸ¥SQLå¤æ‚åº¦å’Œæ½œåœ¨æ”¹è¿›ç‚¹
        if self._has_potential_improvements(sql, nlq):
            return True, "å‘ç°æ½œåœ¨æ”¹è¿›ç‚¹"
        
        # 6. éšæœºé‡‡æ ·ä¿®æ­£ï¼ˆç”¨äºæ¢ç´¢å’Œæµ‹è¯•ï¼‰
        if random.random() < 0.02:  # 10%çš„æ¦‚ç‡å°è¯•ä¿®æ­£
            return True, "éšæœºé€‰æ‹©è¿›è¡Œä¿®æ­£ï¼ˆæ¢ç´¢æ¨¡å¼ï¼‰"
        
        return False, "SQLåˆ¤å®šä¸ºæ— éœ€ä¿®æ­£"

    def _has_potential_improvements(self, sql: str, nlq: str) -> bool:
        """æ£€æŸ¥SQLæ˜¯å¦æœ‰æ½œåœ¨æ”¹è¿›ç‚¹"""
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸å¿…è¦çš„å¤æ‚æ€§
        if sql.count('SELECT') > 1 and len(sql) < 100:
            return True  # çŸ­SQLä¸­æœ‰å¤šä¸ªSELECTå¯èƒ½å¯ä»¥ç®€åŒ–
        
        # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘å¸¸è§çš„ä¼˜åŒ–
        if 'JOIN' in sql.upper() and 'ON' not in sql.upper():
            return True  # JOINä½†æ²¡æœ‰ONæ¡ä»¶
        
        # æ£€æŸ¥åˆ—åå’Œè¡¨åçš„ä¸€è‡´æ€§
        if 'SELECT *' in sql.upper() and any(word in nlq.lower() for word in ['name', 'id', 'count']):
            return True  # é—®é¢˜å¯èƒ½éœ€è¦ç‰¹å®šåˆ—è€Œä¸æ˜¯æ‰€æœ‰åˆ—
        
        return False

    def _generate_improvement_hint(self, sql: str, nlq: str, reason: str) -> str:
        """ä¸ºå¯æ‰§è¡Œä½†å¯èƒ½éœ€è¦æ”¹è¿›çš„SQLç”Ÿæˆæç¤º"""
        
        if "table_name_plural" in reason:
            return "Check if table names should be singular (e.g., 'student' not 'students')"
        elif "column_name_case" in reason:
            return "Check if column names should be lowercase"
        elif "countå‡½æ•°" in reason:
            return "The question asks 'how many', consider using COUNT() function"
        elif "å¹³å‡å€¼" in reason:
            return "The question asks for average, consider using AVG() function"
        elif "æœ€å¤§å€¼" in reason:
            return "The question asks for maximum, consider using MAX() function"
        elif "æœ€å°å€¼" in reason:
            return "The question asks for minimum, consider using MIN() function"
        elif "æ½œåœ¨æ”¹è¿›" in reason:
            return "Review the SQL for potential optimizations or simplifications"
        else:
            return "Review and improve the SQL if possible, but be conservative"

    def _apply_intelligent_fallback_strategy(
        self,
        initial_sql: str,
        initial_validation_result: ExecutionResult,
        corrected_sql: str,
        corrected_validation_result: ExecutionResult
    ) -> Tuple[str, str]:
        """æ™ºèƒ½å›é€€ç­–ç•¥ï¼šç»¼åˆè€ƒè™‘å¤šä¸ªå› ç´ """
        
        # æƒ…å†µ1: ä¿®æ­£SQLå¯æ‰§è¡Œï¼Œåˆå§‹SQLä¸å¯æ‰§è¡Œ -> ä½¿ç”¨ä¿®æ­£SQL
        if (corrected_sql and 
            corrected_validation_result.is_executable and 
            not initial_validation_result.is_executable):
            logger.info("Using corrected SQL (initial was not executable, corrected is executable).")
            return corrected_sql, "corrected"
        
        # æƒ…å†µ2: ä¸¤ä¸ªéƒ½å¯æ‰§è¡Œï¼Œæ¯”è¾ƒå¤æ‚åº¦å’Œåˆç†æ€§
        if (corrected_sql and 
            corrected_validation_result.is_executable and 
            initial_validation_result.is_executable):
            
            # ç®€å•çš„å¯å‘å¼ï¼šæ›´çŸ­çš„SQLå¯èƒ½æ›´å¥½ï¼ˆä½†ä¸ç»å¯¹ï¼‰
            if len(corrected_sql) < len(initial_sql) * 1.2:  # ä¿®æ­£åSQLä¸åº”è¯¥å¤ªé•¿
                logger.info("Using corrected SQL (both executable, corrected seems better).")
                return corrected_sql, "corrected"
            else:
                logger.info("Using initial SQL (corrected SQL seems too complex).")
                return initial_sql, "fallback_corrected_too_complex"
        
        # æƒ…å†µ3: ä¿®æ­£SQLä¸å¯æ‰§è¡Œï¼Œä½†åˆå§‹SQLå¯æ‰§è¡Œ -> å›é€€åˆ°åˆå§‹SQL
        if (initial_validation_result.is_executable and 
            (not corrected_sql or not corrected_validation_result.is_executable)):
            logger.info("Using initial SQL (corrected SQL not executable or empty).")
            return initial_sql, "fallback_to_initial"
        
        # æƒ…å†µ4: ä¸¤ä¸ªéƒ½ä¸å¯æ‰§è¡Œ -> ä½¿ç”¨åˆå§‹SQLï¼ˆè‡³å°‘æ˜¯åŸå§‹çš„ï¼‰
        logger.warning("Both initial and corrected SQL are not executable.")
        return initial_sql, "both_not_executable"

    def _generate_guided_hint(self, initial_sql: str, validation_error: Optional[str]) -> str:
        """æ ¹æ®æ‰§è¡ŒéªŒè¯é”™è¯¯ä¿¡æ¯ç”ŸæˆæŒ‡å¯¼æ€§ Hint"""
        if validation_error:
            error_lower = validation_error.lower()
            
            if "syntax error" in error_lower:
                return "Fix the SQL syntax error only. Do not change table or column names unless necessary."
            elif "no such table" in error_lower or "no such column" in error_lower:
                return "Fix the table/column name error only. Check the schema carefully."
            elif "ambiguous column name" in error_lower:
                return "Fix the ambiguous column reference by adding table alias."
            else:
                return f"Fix this specific error: {validation_error[:100]}. Make minimal changes."
        else:
            return "Fix any execution errors, but make minimal changes to the SQL structure."

    def _format_schema_for_prompt(self, schema: Dict[str, Any]) -> str:
        """å°†ç»“æ„åŒ–çš„Schemaä¿¡æ¯è½¬æ¢ä¸ºè¯¦ç»†çš„æ–‡æœ¬æ ¼å¼"""
        if not schema:
            return "No schema available"
            
        tables = schema.get('table_names_original', [])
        columns = schema.get('column_names_original', [])
        column_types = schema.get('column_types', [])
        primary_keys = schema.get('primary_keys', [])
        foreign_keys = schema.get('foreign_keys', [])
        
        if not tables or not columns:
            return "Schema incomplete"

        # æ„å»ºè¯¦ç»†çš„è¡¨ç»“æ„æè¿°
        schema_text = "Database Schema:\n"
        
        # æŒ‰è¡¨åˆ†ç»„åˆ—ä¿¡æ¯
        table_columns = {}
        for i, (table_id, column_name) in enumerate(columns):
            if table_id == -1:  # è·³è¿‡*å ä½ç¬¦
                continue
            if table_id < len(tables):
                table_name = tables[table_id]
                if table_name not in table_columns:
                    table_columns[table_name] = []
                
                col_info = column_name
                if i < len(column_types):
                    col_info += f" {column_types[i].upper()}"
                if i in primary_keys:
                    col_info += " PRIMARY KEY"
                    
                table_columns[table_name].append(col_info)
        
        # ç”Ÿæˆè¡¨å®šä¹‰
        for table_name, cols in table_columns.items():
            schema_text += f"\nTABLE {table_name} (\n"
            for col in cols:
                schema_text += f"  {col},\n"
            schema_text = schema_text.rstrip(',\n') + "\n);\n"
        
        # æ·»åŠ å¤–é”®å…³ç³»
        if foreign_keys:
            schema_text += "\nForeign Keys:\n"
            for fk in foreign_keys:
                if len(fk) == 2 and fk[0] < len(columns) and fk[1] < len(columns):
                    try:
                        from_table = tables[columns[fk[0]][0]]
                        from_col = columns[fk[0]][1]
                        to_table = tables[columns[fk[1]][0]]
                        to_col = columns[fk[1]][1]
                        schema_text += f"- {from_table}.{from_col} references {to_table}.{to_col}\n"
                    except IndexError:
                        continue  # è·³è¿‡æœ‰é—®é¢˜çš„å¤–é”®å®šä¹‰
        
        return schema_text.strip()

    def _parse_llm_response(self, response_text: str) -> Optional[str]:
        """å¢å¼ºçš„LLMå“åº”è§£æå™¨"""
        if not response_text:
            return None
        
        # æ¸…ç†å“åº”æ–‡æœ¬
        cleaned_text = response_text.strip()
        
        # æ–¹æ³•1: æŸ¥æ‰¾æ˜ç¡®çš„æ ‡è®°
        markers = [
            "Fixed SQL:",
            "Corrected SQL:",
            "Correct SQL:",
            "SQL:",
            "Fixed:"
        ]
        
        for marker in markers:
            if marker in cleaned_text:
                sql_part = cleaned_text.split(marker, 1)[1].strip()
                sql_candidate = self._extract_sql_from_text(sql_part)
                if sql_candidate:
                    return sql_candidate
        
        # æ–¹æ³•2: æŸ¥æ‰¾SQLå…³é”®å­—
        sql_keywords = ["SELECT", "INSERT", "UPDATE", "DELETE", "WITH"]
        for keyword in sql_keywords:
            if keyword in cleaned_text.upper():
                # æ‰¾åˆ°å…³é”®å­—çš„ä½ç½®
                start_idx = cleaned_text.upper().find(keyword)
                sql_part = cleaned_text[start_idx:]
                sql_candidate = self._extract_sql_from_text(sql_part)
                if sql_candidate:
                    return sql_candidate
        
        # æ–¹æ³•3: å¦‚æœåŒ…å«å¸¸è§SQLæ¨¡å¼ï¼Œå°è¯•æ•´ä½“è§£æ
        if any(pattern in cleaned_text.upper() for pattern in ["FROM", "WHERE", "JOIN"]):
            sql_candidate = self._extract_sql_from_text(cleaned_text)
            if sql_candidate:
                return sql_candidate
        
        return None

    def _extract_sql_from_text(self, text: str) -> Optional[str]:
        """ä»æ–‡æœ¬ä¸­æå–SQLè¯­å¥"""
        if not text:
            return None
        
        # æ¸…ç†ä»£ç å—æ ‡è®°
        text = text.strip()
        if text.startswith("```sql"):
            text = text[6:].strip()
        elif text.startswith("```"):
            text = text[3:].strip()
        if text.endswith("```"):
            text = text[:-3].strip()
        
        # å¤„ç†åœæ­¢åºåˆ—
        for stop_seq in self.config.llm_stop_sequences:
            if stop_seq in text:
                text = text.split(stop_seq)[0].strip()
        
        # åˆ†è¡Œå¤„ç†ï¼Œå–ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„SQLè¡Œ
        lines = text.split('\n')
        for line in lines:
            line = line.strip()
            if line and not line.startswith('#') and not line.startswith('--') and not line.startswith('Note:'):
                # ç§»é™¤æœ«å°¾åˆ†å·
                sql_candidate = line.rstrip(';').strip()
                if len(sql_candidate) > 10 and any(keyword in sql_candidate.upper() for keyword in ["SELECT", "INSERT", "UPDATE", "DELETE"]):
                    return sql_candidate
        
        return None

    def _validate_sql(self, sql: str, db_path: str) -> ExecutionResult:
        """éªŒè¯ SQL æŸ¥è¯¢æ˜¯å¦èƒ½æ‰§è¡ŒæˆåŠŸ"""
        if not sql or not db_path:
            return ExecutionResult(False, "SQL or DB path is empty")
        try:
            result = self.sql_validator.execute_sql(sql, db_path)
            return result
        except Exception as e:
            return ExecutionResult(False, f"Validator error: {e}")

    def _save_log(self, log_data: Dict[str, Any]):
        """ä¿å­˜æ—¥å¿—"""
        timestamp = int(time.time())
        log_file_path = os.path.join(
            self.log_dir, 
            f"correction_log_{log_data['db_id']}_{timestamp}.json"
        )
        try:
            with open(log_file_path, 'w', encoding='utf-8') as f:
                json.dump(log_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Failed to save log: {e}")

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ä¿®æ­£æ¨¡å—çš„ç»Ÿè®¡ä¿¡æ¯"""
        log_files = []
        if os.path.exists(self.log_dir):
            log_files = [f for f in os.listdir(self.log_dir) if f.endswith('.json')]
        
        stats = {
            "total_corrections_attempted": len(log_files),
            "log_directory": self.log_dir,
            "config_summary": {
                "model": self.config.llm_model_name,
                "temperature": self.config.llm_temperature,
                "max_tokens": self.config.llm_max_tokens
            }
        }
        
        return stats

def self_correction_main(predict_sqls, db_ids, questions, config_path, output_path=None, detailed_output_path=None):
    """
    æ‰¹é‡è‡ªä¿®æ­£å…¥å£ï¼Œä¾› text2sql.py è°ƒç”¨ã€‚
    Args:
        predict_sqls: List[str]ï¼Œåˆæ­¥ç”Ÿæˆçš„ SQL åˆ—è¡¨
        db_ids: List[str]ï¼Œæ¯æ¡ SQL å¯¹åº”çš„æ•°æ®åº“ ID
        questions: List[str]ï¼Œæ¯æ¡ SQL å¯¹åº”çš„è‡ªç„¶è¯­è¨€é—®é¢˜
        config_path: strï¼Œè‡ªä¿®æ­£é…ç½®æ–‡ä»¶è·¯å¾„
        output_path: strï¼Œæœ€ç»ˆ SQL è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰
        detailed_output_path: strï¼Œè¯¦ç»†æ—¥å¿—è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰
    Returns:
        List[str]ï¼Œä¿®æ­£åçš„ SQL åˆ—è¡¨
    """
    from .config import SelfCorrectionConfig
    import json
    config = SelfCorrectionConfig(config_path)
    module = SelfCorrectionModule(config)
    corrected_sqls = []
    detailed_logs = []
    # å°è¯•ä» config è¯»å– schema_dict å’Œ db_path_dict
    schema_dict = getattr(config, 'schema_dict', {})
    db_path_dict = getattr(config, 'db_path_dict', {})
    default_db_path = getattr(config, 'db_path', None)
    for sql, db_id, question in zip(predict_sqls, db_ids, questions):
        schema = schema_dict.get(db_id, {})
        db_path = db_path_dict.get(db_id, default_db_path)
        corrected_sql, status = module.process(question, schema, sql, db_path)
        corrected_sqls.append(corrected_sql)
        detailed_logs.append({
            "question": question,
            "db_id": db_id,
            "initial_sql": sql,
            "corrected_sql": corrected_sql,
            "status": status
        })
    # ä¿å­˜è¯¦ç»†æ—¥å¿—
    if detailed_output_path:
        with open(detailed_output_path, 'w', encoding='utf-8') as f:
            json.dump(detailed_logs, f, ensure_ascii=False, indent=2)
    # å¯é€‰ï¼šä¿å­˜æœ€ç»ˆ SQL
    if output_path:
        with open(output_path, 'w', encoding='utf-8') as f:
            for sql in corrected_sqls:
                f.write(sql + '\n')
    return corrected_sqls